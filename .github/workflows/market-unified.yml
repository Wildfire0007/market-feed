name: market-unified

on:
  schedule:
    - cron: "*/5 * * * *"   # 5 percenk√©nt (UTC) ‚Äì √©letkor-g√°tl√≥kkal nem spamel
  workflow_dispatch:

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: pages-deploy
  cancel-in-progress: true

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    environment:
      name: github-pages
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      # H-P 08‚Äì22 (Europe/Budapest); h√©tv√©g√©n/√©jjel skip
      - name: Gate by local time (Europe/Budapest)
        shell: bash
        run: |
          TZ="Europe/Budapest"
          HOUR=$(TZ=$TZ date +%H)
          DOW=$(TZ=$TZ date +%u)   # 1=h√©tf≈ë ‚Ä¶ 7=vas√°rnap
          if [ "$DOW" -ge 6 ]; then
            echo "Weekend ‚Üí skip"
            exit 0
          fi
          if [ "$HOUR" -lt 8 ] || [ "$HOUR" -gt 22 ]; then
            echo "Outside 08‚Äì22 local ‚Üí skip"
            exit 0
          fi

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: ${{ runner.os }}-pip-

      - name: Install deps
        run: |
          python -V
          pip install --upgrade pip
          pip install -r requirements.txt

      # <<< MINDH√ÅROM ESZK√ñZ EGY FUT√ÅSBAN >>>
      - name: Generate feeds (SOL + NSDQ100 + GOLD_CFD)
        env:
          TWELVEDATA_API_KEY: ${{ secrets.TWELVEDATA_API_KEY }}
          FINNHUB_API_KEY: ${{ secrets.FINNHUB_API_KEY }} 
          TD_PAUSE: "2.0"
          ASSET_ONLY: "SOL,NSDQ100,GOLD_CFD"
          TD_M5_MIN_AGE: "900"
          TD_H1_MIN_AGE: "3600"
          TD_H4_MIN_AGE: "14400"
          DEBUG: "1"
        run: python Trading.py

      - name: Ensure jq (for JSON merge)
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq

      # R√©gi (Trading.py √°ltal √≠rt) summary t√∂rl√©se ‚Äì mindig a merged legyen kint
      - name: Remove legacy summaries (from Trading.py)
        run: |
          rm -f public/analysis_summary.json public/analysis.html || true

      # A h√°rom signal.json-b√≥l egys√©ges summary
      - name: Build merged analysis_summary.json (3 asset)
        shell: bash
        run: |
          set -euo pipefail

          mkdir -p public/SOL public/NSDQ100 public/GOLD_CFD
          ensure_sig() {
            A="$1"; F="public/$A/signal.json"
            if [ ! -f "$F" ]; then
              echo "{\"asset\":\"$A\",\"ok\":false,\"signal\":\"no entry\",\"reasons\":[\"missing signal.json\"]}" > "$F"
            fi
          }
          ensure_sig SOL
          ensure_sig NSDQ100
          ensure_sig GOLD_CFD

          UPDATED="$(date -u +%FT%TZ)"
          jq -n --arg ts "$UPDATED" \
            --slurpfile sol public/SOL/signal.json \
            --slurpfile ndx public/NSDQ100/signal.json \
            --slurpfile xau public/GOLD_CFD/signal.json \
            '{
               ok:true,
               updated_utc:$ts,
               assets:{ SOL:$sol[0], NSDQ100:$ndx[0], GOLD_CFD:$xau[0] }
             }' > public/analysis_summary.json

          # Opcion√°lis HTML (emberi n√©zet)
          cat > public/analysis.html <<'HTML'
          <!doctype html><meta charset="utf-8"><title>Analysis</title>
          <h1>Analysis summary</h1><pre id="out"></pre>
          <script>
          fetch('./analysis_summary.json').then(r=>r.json())
            .then(j=>{document.getElementById('out').textContent=JSON.stringify(j,null,2);});
          </script>
          HTML

      - name: Post summary to Discord (only if there is an Entry)
        if: ${{ success() }}
        env:
          DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
        shell: bash
        run: |
          set -euo pipefail

          # 0) Friss-e az √∂sszegz≈ë? (<= 25 perc)
          updated=$(jq -r '.updated_utc' public/analysis_summary.json)
          now=$(date -u +%s)
          upd=$(date -u -d "$updated" +%s || echo 0)
          age=$(( now - upd ))
          if [ "$upd" -eq 0 ] || [ "$age" -gt 1500 ]; then
            echo "Stale data ($age s) ‚Üí skip"
            exit 0
          fi

          # 1) Alap jelek
          sol=$(jq -r '.assets.SOL.signal' public/analysis_summary.json)
          ndx=$(jq -r '.assets.NSDQ100.signal' public/analysis_summary.json)
          xau=$(jq -r '.assets.GOLD_CFD.signal' public/analysis_summary.json)

          # 1/b) Spot √°rak (USD) ‚Äì csak ki√≠r√°shoz
          solp=$(jq -r '.price_usd // empty' public/SOL/spot.json)
          ndxp=$(jq -r '.price_usd // empty' public/NSDQ100/spot.json)
          xaup=$(jq -r '.price_usd // empty' public/GOLD_CFD/spot.json)
          fmt() { v="$1"; if [ -z "$v" ] || [ "$v" = "null" ]; then echo "?"; else printf '%.2f' "$v"; fi; }
          solp=$(fmt "$solp"); ndxp=$(fmt "$ndxp"); xaup=$(fmt "$xaup")

          # 2) Riport beolvas√°sa √©s Bel√©p≈ë(k) kinyer√©se
          mkdir -p tmp
          curl -fLsS -o tmp/report.md \
            https://raw.githubusercontent.com/Wildfire0007/market-feed/main/reports/latest/analysis_report.md || true

          printf '%s\n' \
            'import re, json, os' \
            'out = {}' \
            'p = "tmp/report.md"' \
            'if os.path.isfile(p) and os.path.getsize(p) > 0:' \
            '    txt = open(p, "r", encoding="utf-8", errors="ignore").read()' \
            '    def section(asset):' \
            '        m = re.search(rf"(?mi)^##+\s*{asset}\b.*?(?=^##\s|\Z)", txt, re.M|re.S)' \
            '        return m.group(0) if m else ""' \
            '    def entry(block):' \
            '        m = re.search(r"(?mi)^###?\s*Bel√©p≈ë.*?(?=^##|\Z)", block, re.M|re.S)' \
            '        if not m: return None' \
            '        b = m.group(0)' \
            '        def g(rx):' \
            '            mm = re.search(rx, b, re.I)' \
            '            return mm.group(1).strip().replace(",", ".") if mm else None' \
            '        side = g(r"\b(LONG|SHORT)\b")' \
            '        entryp = g(r"Entry[:\s]*([\d\.,]+)")' \
            '        sl = g(r"SL[:\s]*([\d\.,]+)")' \
            '        tp1 = g(r"TP1[:\s]*([\d\.,]+)")' \
            '        tp2 = g(r"TP2[:\s]*([\d\.,]+)")' \
            '        prob = g(r"prob[^0-9%]*([\d\.]+)")' \
            '        d = {}' \
            '        if side: d["side"] = side' \
            '        if entryp: d["entry"] = entryp' \
            '        if sl: d["sl"] = sl' \
            '        if tp1: d["tp1"] = tp1' \
            '        if tp2: d["tp2"] = tp2' \
            '        if prob: d["prob"] = prob' \
            '        return d if d else None' \
            '    for a in ["SOL","NSDQ100","GOLD_CFD"]:' \
            '        e = entry(section(a))' \
            '        if e: out[a] = e' \
            'open("tmp/entries.json", "w", encoding="utf-8").write(json.dumps(out, ensure_ascii=False))' \
            > tmp/parse_entries.py

          python tmp/parse_entries.py || true

          # 2/b) Ha nincs bel√©p≈ë ‚Üí nincs √©rtes√≠t√©s
          if [ ! -s tmp/entries.json ] || [ "$(jq -r 'keys|length' tmp/entries.json 2>/dev/null || echo 0)" = "0" ]; then
            echo "No actionable entry ‚Üí skip Discord"
            exit 0
          fi

          # 2/c) Duplik√°tum-sz≈±r√©s CSAK a bel√©p≈ëk tartalma alapj√°n
          entries_hash=$(sha256sum tmp/entries.json | cut -d' ' -f1)
          curl -fLsS -o tmp/prev_hash.txt https://wildfire0007.github.io/market-feed/.last_discord_hash || true
          prev_hash=$(cat tmp/prev_hash.txt 2>/dev/null || echo "")
          if [ "$entries_hash" = "$prev_hash" ]; then
            echo "Same entries as last alert ‚Üí skip"
            exit 0
          fi

          # 3) √úzenet √∂ssze√°ll√≠t√°s (sz√©p sort√∂r√©sekkel)
          bell=$(jq -r '
              to_entries
              | map(
                  "üîî Bel√©p≈ë ‚Ä¢ " + .key + " ‚Ä¢ " + (.value.side // "?") + " ‚Ä¢ " +
                  ([
                    (if .value.entry then "entry=" + .value.entry else empty end),
                    (if .value.sl    then "SL="    + .value.sl    else empty end),
                    (if .value.tp1   then "TP1="   + .value.tp1   else empty end),
                    (if .value.tp2   then "TP2="   + .value.tp2   else empty end),
                    (if .value.prob  then "prob="  + .value.prob  + "%" else empty end)
                  ] | join(", "))
                )
              | .[]
            ' tmp/entries.json)

          url="https://wildfire0007.github.io/market-feed/analysis.html"
          header="üïí ${updated} ‚Ä¢ market-feed"
          lines="SOL ‚Ä¢ ${sol} ‚Ä¢ \$${solp}\nNSDQ100 ‚Ä¢ ${ndx} ‚Ä¢ \$${ndxp}\nGOLD_CFD ‚Ä¢ ${xau} ‚Ä¢ \$${xaup}"

          msg="${header}
          ${lines}
          ${bell}
          üîó ${url}"

          # @here csak bel√©p≈ë eset√©n (most mindig van, hisz gatingelt√ºnk)
          payload=$(jq -n --arg content "@here ${msg}" \
                     '{content:$content, allowed_mentions:{parse:["everyone"]}}')

          curl -fsS -H "Content-Type: application/json" -d "$payload" "$DISCORD_WEBHOOK_URL"

          # duplik√°tum-sz≈±r√©shez: bel√©p≈ëk hash-e ker√ºlj√∂n a Pages-re
          echo "$entries_hash" > public/.last_discord_hash


      - name: Ensure index.html
        run: |
          mkdir -p public
          printf '%s\n' \
            '<!doctype html><meta charset="utf-8"><title>market-feed</title>' \
            '<h1>market-feed</h1><ul>' \
            '<li><a href="./analysis_summary.json">analysis_summary.json</a></li>' \
            '<li><a href="./analysis.html">analysis.html</a></li>' \
            '<li><a href="./SOL/signal.json">SOL/signal.json</a></li>' \
            '<li><a href="./NSDQ100/signal.json">NSDQ100/signal.json</a></li>' \
            '<li><a href="./GOLD_CFD/signal.json">GOLD_CFD/signal.json</a></li>' \
            '</ul>' > public/index.html

      - name: Configure Pages
        uses: actions/configure-pages@v5

      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: public

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
