name: market-unified

on:
  schedule:
    - cron: "*/5 * * * *"   # 5 percenk√©nt (UTC) ‚Äì √©letkor-g√°tl√≥kkal nem spamel
  workflow_dispatch:

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: pages-deploy
  cancel-in-progress: true

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    environment:
      name: github-pages
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      # H-P 08‚Äì22 (Europe/Budapest); h√©tv√©g√©n/√©jjel skip
      - name: Gate by local time (Europe/Budapest)
        shell: bash
        run: |
          TZ="Europe/Budapest"
          HOUR=$(TZ=$TZ date +%H)
          DOW=$(TZ=$TZ date +%u)   # 1=h√©tf≈ë ‚Ä¶ 7=vas√°rnap
          if [ "$DOW" -ge 6 ]; then
            echo "Weekend ‚Üí skip"
            exit 0
          fi
          if [ "$HOUR" -lt 8 ] || [ "$HOUR" -gt 22 ]; then
            echo "Outside 08‚Äì22 local ‚Üí skip"
            exit 0
          fi

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: ${{ runner.os }}-pip-

      - name: Install deps
        run: |
          python -V
          pip install --upgrade pip
          pip install -r requirements.txt

      # <<< MINDH√ÅROM ESZK√ñZ EGY FUT√ÅSBAN >>>
      - name: Generate feeds (SOL + NSDQ100 + GOLD_CFD)
        env:
          TWELVEDATA_API_KEY: ${{ secrets.TWELVEDATA_API_KEY }}
          TD_PAUSE: "2.0"
          ASSET_ONLY: "SOL,NSDQ100,GOLD_CFD"
          TD_M5_MIN_AGE: "900"      # 5m OHLC csak 15 perc ut√°n friss√ºl
          TD_H1_MIN_AGE: "3600"     # 1h OHLC csak 1 √≥ra ut√°n friss√ºl
          TD_H4_MIN_AGE: "14400"    # 4 √≥ra
          DEBUG: "1"
        run: python Trading.py

      - name: Ensure jq (for JSON merge)
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq

      # R√©gi (Trading.py √°ltal √≠rt) summary t√∂rl√©se ‚Äì mindig a merged legyen kint
      - name: Remove legacy summaries (from Trading.py)
        run: |
          rm -f public/analysis_summary.json public/analysis.html || true

      # A h√°rom signal.json-b√≥l egys√©ges summary
      - name: Build merged analysis_summary.json (3 asset)
        shell: bash
        run: |
          set -euo pipefail

          mkdir -p public/SOL public/NSDQ100 public/GOLD_CFD
          ensure_sig() {
            A="$1"; F="public/$A/signal.json"
            if [ ! -f "$F" ]; then
              echo "{\"asset\":\"$A\",\"ok\":false,\"signal\":\"no entry\",\"reasons\":[\"missing signal.json\"]}" > "$F"
            fi
          }
          ensure_sig SOL
          ensure_sig NSDQ100
          ensure_sig GOLD_CFD

          UPDATED="$(date -u +%FT%TZ)"
          jq -n --arg ts "$UPDATED" \
            --slurpfile sol public/SOL/signal.json \
            --slurpfile ndx public/NSDQ100/signal.json \
            --slurpfile xau public/GOLD_CFD/signal.json \
            '{
               ok:true,
               updated_utc:$ts,
               assets:{ SOL:$sol[0], NSDQ100:$ndx[0], GOLD_CFD:$xau[0] }
             }' > public/analysis_summary.json

          # Opcion√°lis HTML (emberi n√©zet)
          cat > public/analysis.html <<'HTML'
          <!doctype html><meta charset="utf-8"><title>Analysis</title>
          <h1>Analysis summary</h1><pre id="out"></pre>
          <script>
          fetch('./analysis_summary.json').then(r=>r.json())
            .then(j=>{document.getElementById('out').textContent=JSON.stringify(j,null,2);});
          </script>
          HTML

      - name: Post summary to Discord (with optional Entry/SL/TP)
        if: ${{ success() }}
        env:
          DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
        shell: bash
        run: |
          set -euo pipefail

          # 0) Friss-e az √∂sszegz≈ë? (<= 25 perc)
          updated=$(jq -r '.updated_utc' public/analysis_summary.json)
          now=$(date -u +%s)
          upd=$(date -u -d "$updated" +%s || echo 0)
          age=$(( now - upd ))
          if [ "$upd" -eq 0 ] || [ "$age" -gt 1500 ]; then
            echo "Stale data ($age s) ‚Üí skip Discord post"
            exit 0
          fi

          # 0/b) Duplik√°tum-sz≈±r√©s (ha nem v√°ltozott semmi, skip)
          mkdir -p tmp
          # jelenlegi √°llapot lenyomata (hash): updated_utc + 3 signal + (opcion√°lis) entries.json tartalom
          base_hash=$(jq -r '[.updated_utc, .assets.SOL.signal, .assets.NSDQ100.signal, .assets.GOLD_CFD.signal] | join("|")' public/analysis_summary.json)
          curl -fLsS -o tmp/report.md https://raw.githubusercontent.com/Wildfire0007/market-feed/main/reports/latest/analysis_report.md || true
          # durva lenyomat a reportb√≥l (ha van)
          rpt_hash=$(sha256sum tmp/report.md 2>/dev/null | cut -d' ' -f1 || echo "no-report")
          new_hash=$(printf '%s|%s' "$base_hash" "$rpt_hash" | sha256sum | cut -d' ' -f1)

          # el≈ëz≈ë hash let√∂lt√©se a Pages-r≈ël (ha m√°r volt deploy)
          curl -fLsS -o tmp/prev_hash.txt https://wildfire0007.github.io/market-feed/.last_discord_hash || true
          prev_hash=$(cat tmp/prev_hash.txt 2>/dev/null || echo "")

          if [ "$new_hash" = "$prev_hash" ]; then
            echo "No change since last post ‚Üí skip Discord post"
            exit 0
          fi

          # 1) Alap jelek
          sol=$(jq -r '.assets.SOL.signal' public/analysis_summary.json)
          ndx=$(jq -r '.assets.NSDQ100.signal' public/analysis_summary.json)
          xau=$(jq -r '.assets.GOLD_CFD.signal' public/analysis_summary.json)

          # 2) Riport let√∂lt√©se (ha van)
          mkdir -p tmp
          curl -fLsS -o tmp/report.md \
            https://raw.githubusercontent.com/Wildfire0007/market-feed/main/reports/latest/analysis_report.md || true

          # 3) Kis Python f√°jl here-doc n√©lk√ºl (printf-fel), hogy kinyerj√ºk a Bel√©p≈ë blokkokat
          printf '%s\n' \
            'import re, json, os' \
            'out = {}' \
            'p = "tmp/report.md"' \
            'if os.path.isfile(p) and os.path.getsize(p) > 0:' \
            '    txt = open(p, "r", encoding="utf-8", errors="ignore").read()' \
            '    def section(asset):' \
            '        m = re.search(rf"(?mi)^##+\\s*{asset}\\b.*?(?=^##\\s|\\Z)", txt, re.M|re.S)' \
            '        return m.group(0) if m else ""' \
            '    def entry(block):' \
            '        m = re.search(r"(?mi)^###?\\s*Bel√©p≈ë.*?(?=^##|\\Z)", block, re.M|re.S)' \
            '        if not m: return None' \
            '        b = m.group(0)' \
            '        def g(rx):' \
            '            mm = re.search(rx, b, re.I)' \
            '            return mm.group(1).strip().replace(\",\", \".\") if mm else None' \
            '        side = g(r"\\b(LONG|SHORT)\\b")' \
            '        entryp = g(r"Entry[:\\s]*([\\d\\.,]+)")' \
            '        sl = g(r"SL[:\\s]*([\\d\\.,]+)")' \
            '        tp1 = g(r"TP1[:\\s]*([\\d\\.,]+)")' \
            '        tp2 = g(r"TP2[:\\s]*([\\d\\.,]+)")' \
            '        prob = g(r"prob[^0-9%]*([\\d\\.]+)")' \
            '        d = {}' \
            '        if side: d["side"] = side' \
            '        if entryp: d["entry"] = entryp' \
            '        if sl: d["sl"] = sl' \
            '        if tp1: d["tp1"] = tp1' \
            '        if tp2: d["tp2"] = tp2' \
            '        if prob: d["prob"] = prob' \
            '        return d if d else None' \
            '    for a in ["SOL","NSDQ100","GOLD_CFD"]:' \
            '        e = entry(section(a))' \
            '        if e: out[a] = e' \
            'open("tmp/entries.json", "w", encoding="utf-8").write(json.dumps(out, ensure_ascii=False))' \
            > tmp/parse_entries.py

          python tmp/parse_entries.py || true

          bell=""
          if [ -s tmp/entries.json ] && [ "$(jq -r 'keys|length' tmp/entries.json 2>/dev/null || echo 0)" != "0" ]; then
            bell=$(jq -r '
              to_entries
              | map(
                  "üîî Bel√©p≈ë ‚Ä¢ " + .key + " ‚Ä¢ " + (.value.side // "?") + " ‚Ä¢ " +
                  ([
                    (if .value.entry then "entry=" + .value.entry else empty end),
                    (if .value.sl    then "SL="    + .value.sl    else empty end),
                    (if .value.tp1   then "TP1="   + .value.tp1   else empty end),
                    (if .value.tp2   then "TP2="   + .value.tp2   else empty end),
                    (if .value.prob  then "prob="  + .value.prob  + "%" else empty end)
                  ] | join(", "))
                )
              | .[]
            ' tmp/entries.json)
          fi

          url="https://wildfire0007.github.io/market-feed/analysis.html"
          header="üïí ${updated} ‚Ä¢ market-feed"
          lines="SOL ‚Ä¢ ${sol}\nNSDQ100 ‚Ä¢ ${ndx}\nGOLD_CFD ‚Ä¢ ${xau}"

          msg="${header}
          ${lines}"
          if [ -n "$bell" ]; then
            msg="${msg}
          ${bell}"
          fi
          msg="${msg}
          üîó ${url}"

          payload=$(jq -n --arg content "$msg" '{content:$content}')
          curl -fsS -H "Content-Type: application/json" \
               -d "$payload" "$DISCORD_WEBHOOK_URL"
          # √∫j hash elment√©se a Pages-re (artifact r√©sze lesz)
          echo "$new_hash" > public/.last_discord_hash



      - name: Ensure index.html
        run: |
          mkdir -p public
          printf '%s\n' \
            '<!doctype html><meta charset="utf-8"><title>market-feed</title>' \
            '<h1>market-feed</h1><ul>' \
            '<li><a href="./analysis_summary.json">analysis_summary.json</a></li>' \
            '<li><a href="./analysis.html">analysis.html</a></li>' \
            '<li><a href="./SOL/signal.json">SOL/signal.json</a></li>' \
            '<li><a href="./NSDQ100/signal.json">NSDQ100/signal.json</a></li>' \
            '<li><a href="./GOLD_CFD/signal.json">GOLD_CFD/signal.json</a></li>' \
            '</ul>' > public/index.html

      - name: Configure Pages
        uses: actions/configure-pages@v5

      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: public

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
