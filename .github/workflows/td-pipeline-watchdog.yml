name: TD Pipeline Watchdog

on:
  schedule:
    # GitHub Actions schedule minimum: 5 perc.
    # Watchdog fallback dispatch-eli a TD pipeline-t, ha kimarad egy ütem.
    - cron: "*/5 * * * *"
    # Második, eltolva futó ütem: kisebb esélye van annak, hogy egyszerre maradnak ki.
    - cron: "2-59/5 * * * *"  
  workflow_dispatch:

permissions:
  actions: write
  contents: read

jobs:
  ensure_td_pipeline_fresh:
    runs-on: ubuntu-24.04
    timeout-minutes: 5
    steps:
      - name: Check TD pipeline freshness and dispatch if stale
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          TD_BOT_PAT: ${{ secrets.TD_BOT_PAT }}
        run: |
          python3 - <<'PY'
          import json
          import os
          import time
          import urllib.error
          import urllib.request
          from datetime import datetime, timezone

          repo = os.environ.get("GITHUB_REPOSITORY", "")
          if "/" not in repo:
            raise SystemExit(f"Invalid GITHUB_REPOSITORY: {repo}")

          owner, name = repo.split("/", 1)
          workflow_id = "td-pipeline.yml"
          branch = "main"
          max_gap_minutes = 7
          max_running_minutes = 8
          max_queued_minutes = 3
          api_base = f"https://api.github.com/repos/{owner}/{name}"

          def github_request(method: str, url: str, token: str, payload: dict | None = None):
            data = None
            headers = {
              "Accept": "application/vnd.github+json",
              "Authorization": f"Bearer {token}",
              "X-GitHub-Api-Version": "2022-11-28",
            }
            if payload is not None:
              data = json.dumps(payload).encode("utf-8")
              headers["Content-Type"] = "application/json"
            req = urllib.request.Request(url, data=data, method=method, headers=headers)
            with urllib.request.urlopen(req, timeout=30) as resp:
              return resp.status, json.loads(resp.read().decode("utf-8"))

          def list_runs(token: str):
            url = f"{api_base}/actions/workflows/{workflow_id}/runs?branch={branch}&per_page=20"
            status, payload = github_request("GET", url, token)
            if status != 200:
              raise SystemExit(f"Failed listing runs ({status})")
            return payload.get("workflow_runs", [])

          runs = list_runs(os.environ["GH_TOKEN"])
          now = datetime.now(timezone.utc)
          in_progress = [r for r in runs if r.get("status") == "in_progress"]
          queued = [r for r in runs if r.get("status") == "queued"]
          latest_effective = next((r for r in runs if r.get("run_started_at") or r.get("status") == "completed"), None)

          if latest_effective:
            basis = latest_effective.get("run_started_at") or latest_effective.get("created_at")
            latest_age_minutes = (now - datetime.fromisoformat(basis.replace("Z", "+00:00"))).total_seconds() / 60.0
          else:
            latest_age_minutes = float("inf")

          healthy_running = any(
            (now - datetime.fromisoformat((r.get("run_started_at") or r.get("created_at")).replace("Z", "+00:00"))).total_seconds() / 60.0 <= max_running_minutes
            for r in in_progress
          )
          stale_queued = any(
            (now - datetime.fromisoformat(r.get("created_at", "").replace("Z", "+00:00"))).total_seconds() / 60.0 >= max_queued_minutes
            for r in queued
            if r.get("created_at")
          )
          stale_queued_runs = [
            r for r in queued
            if r.get("created_at") and (
              (now - datetime.fromisoformat(r.get("created_at").replace("Z", "+00:00"))).total_seconds() / 60.0 >= max_queued_minutes
            )
          ]

          print(f"latest_age_min={latest_age_minutes:.2f}" if latest_age_minutes != float("inf") else "latest_age_min=none")
          print(f"in_progress={len(in_progress)} queued={len(queued)}")

          if healthy_running:
            print("freshness=ok reason=healthy_running")
            raise SystemExit(0)

          if latest_age_minutes <= max_gap_minutes:
            print("freshness=ok reason=within_gap")
            raise SystemExit(0)

          if queued and not stale_queued:
            print("freshness=ok reason=fresh_queue")
            raise SystemExit(0)

          # Clear stale queued runs to avoid lock-in where old queued items block recovery.
          for run in stale_queued_runs:
            run_id = run.get("id")
            if not run_id:
              continue
            cancel_url = f"{api_base}/actions/runs/{run_id}/cancel"
            cancel_error = ""
            try:
              cancel_status, _ = github_request("POST", cancel_url, os.environ["GH_TOKEN"])
              if cancel_status not in {202, 409}:
                cancel_error = f"GH_TOKEN HTTP {cancel_status}"
            except urllib.error.HTTPError as exc:
              cancel_error = f"GH_TOKEN HTTP {exc.code}: {exc.read().decode('utf-8', errors='replace')}"

            if cancel_error and os.environ.get("TD_BOT_PAT"):
              try:
                cancel_status, _ = github_request("POST", cancel_url, os.environ["TD_BOT_PAT"])
                if cancel_status not in {202, 409}:
                  cancel_error = f"TD_BOT_PAT HTTP {cancel_status}"
                else:
                  cancel_error = ""
              except urllib.error.HTTPError as exc:
                cancel_error = f"TD_BOT_PAT HTTP {exc.code}: {exc.read().decode('utf-8', errors='replace')}"

            if cancel_error:
              print(f"queued_cancel_warning run_id={run_id} error={cancel_error}")
            else:
              print(f"queued_cancel_ok run_id={run_id}")

          dispatch_url = f"{api_base}/actions/workflows/{workflow_id}/dispatches"
          dispatch_payload = {"ref": branch, "inputs": {"force_public_sync": "true"}}
          dispatch_started_at = datetime.now(timezone.utc)

          dispatch_error = ""
          dispatched_with = "GH_TOKEN"
          try:
            status, _ = github_request("POST", dispatch_url, os.environ["GH_TOKEN"], dispatch_payload)
            if status != 204:
              dispatch_error = f"GH_TOKEN HTTP {status}"
          except urllib.error.HTTPError as exc:
            dispatch_error = f"GH_TOKEN HTTP {exc.code}: {exc.read().decode('utf-8', errors='replace')}"

          if dispatch_error and os.environ.get("TD_BOT_PAT"):
            try:
              status, _ = github_request("POST", dispatch_url, os.environ["TD_BOT_PAT"], dispatch_payload)
              if status == 204:
                dispatch_error = ""
                dispatched_with = "TD_BOT_PAT"
              else:
                dispatch_error = f"TD_BOT_PAT HTTP {status}"
            except urllib.error.HTTPError as exc:
              dispatch_error = f"TD_BOT_PAT HTTP {exc.code}: {exc.read().decode('utf-8', errors='replace')}"

          if dispatch_error:
            raise SystemExit(f"dispatch_failed={dispatch_error}")

          # Validate: within ~25 seconds a NEW queued/in_progress run should appear.
          dispatched = False
          for _ in range(5):
            time.sleep(5)
            refreshed = list_runs(os.environ["GH_TOKEN"])
            for run in refreshed:
              created_at = run.get("created_at")
              if run.get("status") not in {"queued", "in_progress"} or not created_at:
                continue
              created_dt = datetime.fromisoformat(created_at.replace("Z", "+00:00"))
              if created_dt >= dispatch_started_at:
                dispatched = True
                break
            if dispatched:
              break
 
          if not dispatched:
            raise SystemExit("dispatch_requested_but_no_new_queued_run_detected")

          print(f"dispatch=ok token={dispatched_with}")
          PY
