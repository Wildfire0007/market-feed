"""JSON pipeline backtester.

The script walks through a directory that mirrors the ``public`` output tree
and aggregates gate statistics.  Each subdirectory is treated as a snapshot in
time (typically a UTC timestamp) that contains ``<ASSET>/signal.json`` objects
generated by ``analysis.py``.  The backtester is therefore able to evaluate the
impact of ATR / Fib gates, P-score changes and sentiment overrides without the
need for broker connectivity.

Example usage::

    python -m scripts.backtest --root reports/history --asset BTCUSD

"""

from __future__ import annotations

import argparse
import json
from collections import Counter
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional

import pandas as pd


@dataclass
class Snapshot:
    timestamp: str
    asset: str
    payload: Dict[str, Any]


def iter_snapshots(root: Path, asset: Optional[str] = None) -> Iterable[Snapshot]:
    for ts_dir in sorted(root.iterdir()):
        if not ts_dir.is_dir():
            continue
        for candidate in ts_dir.glob("*/signal.json"):
            asset_name = candidate.parent.name
            if asset and asset_name.upper() != asset.upper():
                continue
            try:
                with candidate.open("r", encoding="utf-8") as fh:
                    payload = json.load(fh)
            except Exception:
                continue
            yield Snapshot(timestamp=ts_dir.name, asset=asset_name.upper(), payload=payload)


def summarise(snapshots: Iterable[Snapshot]) -> pd.DataFrame:
    rows: List[Dict[str, Any]] = []
    for snap in snapshots:
        gates = snap.payload.get("gates", {})
        missing = gates.get("missing", []) if isinstance(gates, dict) else []
        rr = snap.payload.get("rr")
        rel_atr = snap.payload.get("active_position_meta", {}).get("atr5_rel")
        fib = "Fib zÃ³na" in " ".join(snap.payload.get("reasons", []))
        rows.append(
            {
                "timestamp": snap.timestamp,
                "asset": snap.asset,
                "signal": snap.payload.get("signal"),
                "probability": snap.payload.get("probability"),
                "rr": rr,
                "missing": ",".join(sorted(set(missing))),
                "p_score": snap.payload.get("probability"),
                "rel_atr": rel_atr,
                "fib_confluence": fib,
            }
        )
    return pd.DataFrame(rows)


def main() -> None:
    parser = argparse.ArgumentParser(description="Aggregate analysis snapshots for research")
    parser.add_argument("--root", required=True, help="Directory containing timestamped public snapshots")
    parser.add_argument("--asset", help="Optional asset filter")
    parser.add_argument("--csv", help="Optional path to write the aggregated CSV")
    args = parser.parse_args()

    root = Path(args.root)
    if not root.exists():
        raise SystemExit(f"Snapshot root {root} does not exist")

    df = summarise(iter_snapshots(root, args.asset))
    if df.empty:
        raise SystemExit("No snapshots found. Ensure the --root directory matches the exported history.")

    grouped = df.groupby(["asset", "signal"]).size().unstack(fill_value=0)
    print("Signal distribution:\n", grouped)

    missing_counter = Counter()
    for entry in df["missing"]:
        if not entry:
            continue
        for gate in entry.split(","):
            missing_counter[gate] += 1
    print("\nTop blocking gates:")
    for gate, count in missing_counter.most_common():
        print(f"  {gate or 'n/a'}: {count}")

    if args.csv:
        csv_path = Path(args.csv)
        csv_path.parent.mkdir(parents=True, exist_ok=True)
        df.to_csv(csv_path, index=False)
        print(f"\nWritten aggregated dataset to {csv_path}")


if __name__ == "__main__":
    main()
