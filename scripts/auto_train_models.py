#!/usr/bin/env python3
"""Automate the Feature → Label → Train loop for configured assets.

This helper glues together the existing ``make_labels.py`` and
``train_models.py`` CLIs so a single command (or CI job) can refresh the
feature snapshots, derive labels and persist new GradientBoosting models.
"""
from __future__ import annotations

import argparse
import os
import subprocess
import sys
from pathlib import Path
from typing import Iterable, List, Sequence

import pandas as pd

_PROJECT_ROOT = Path(__file__).resolve().parents[1]
if str(_PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(_PROJECT_ROOT))

from config.analysis_settings import ASSETS  # noqa: E402

DEFAULT_LABEL_METHOD = "tbm"
DEFAULT_HORIZON = 48
DEFAULT_THRESHOLD = 0.0
DEFAULT_PT = 0.01
DEFAULT_SL = 0.01
DEFAULT_MIN_SAMPLES = 25


def _parse_args(argv: Sequence[str] | None = None) -> argparse.Namespace:
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument(
        "--assets",
        nargs="*",
        help="Optional whitelist of assets to refresh (default: all configured)",
    )
    parser.add_argument(
        "--public-dir",
        default=os.getenv("PUBLIC_DIR", "public"),
        help="Root directory containing ml_features/, models/ and price caches",
    )
    parser.add_argument(
        "--label-method",
        choices=["realized", "fixed", "tbm"],
        default=DEFAULT_LABEL_METHOD,
        help="Labelling strategy forwarded to make_labels.py",
    )
    parser.add_argument(
        "--label-column",
        default="label",
        help="Name of the label column generated by the labelling step",
    )
    parser.add_argument(
        "--horizon",
        type=int,
        default=DEFAULT_HORIZON,
        help="Forward horizon/vertical barrier when using fixed/tbm methods",
    )
    parser.add_argument(
        "--threshold",
        type=float,
        default=DEFAULT_THRESHOLD,
        help="Return threshold for the fixed-horizon method",
    )
    parser.add_argument(
        "--pt",
        type=float,
        default=DEFAULT_PT,
        help="Take-profit multiplier for the TBM labelling method",
    )
    parser.add_argument(
        "--sl",
        type=float,
        default=DEFAULT_SL,
        help="Stop-loss multiplier for the TBM labelling method",
    )
    parser.add_argument(
        "--min-samples",
        type=int,
        default=DEFAULT_MIN_SAMPLES,
        help="Minimum labelled rows required before training is attempted",
    )
    parser.add_argument(
        "--skip-label",
        action="store_true",
        help="Reuse an existing labelled dataset instead of regenerating it",
    )
    parser.add_argument(
        "--skip-train",
        action="store_true",
        help="Only run the labelling step without fitting new models",
    )
    parser.add_argument(
        "--skip-readiness",
        action="store_true",
        help="Do not run check_ml_readiness.py after training completes",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Forward --dry-run to train_models.py to skip persisting artefacts",
    )
    return parser.parse_args(argv)


def _normalise_assets(assets: Iterable[str] | None) -> List[str]:
    if not assets:
        return sorted(ASSETS)
    return sorted({asset.upper() for asset in assets})


def _python() -> str:
    return sys.executable or "python3"


def _run_step(label: str, cmd: Sequence[str], env: dict[str, str]) -> None:
    pretty = " ".join(cmd)
    print(f"\n▶ {label}: {pretty}")
    result = subprocess.run(cmd, cwd=_PROJECT_ROOT, env=env)
    if result.returncode != 0:
        raise SystemExit(f"{label} failed with exit code {result.returncode}")


def _count_labelled_rows(path: Path, label_column: str) -> int:
    try:
        frame = pd.read_csv(path)
    except FileNotFoundError:
        return 0
    except Exception as exc:  # pragma: no cover - defensive
        print(f"⚠️  Failed to read {path}: {exc}")
        return 0

    if label_column not in frame.columns:
        return 0
    return int(frame[label_column].dropna().shape[0])


def main(argv: Sequence[str] | None = None) -> int:
    args = _parse_args(argv)
    assets = _normalise_assets(args.assets)

    public_dir = Path(args.public_dir).expanduser().resolve()
    features_dir = public_dir / "ml_features"
    model_dir = public_dir / "models"

    env = os.environ.copy()
    env["PUBLIC_DIR"] = str(public_dir)

    python = _python()

    if not features_dir.exists():
        raise SystemExit(f"Feature directory not found: {features_dir}")

    for asset in assets:
        feature_path = features_dir / f"{asset}_features.csv"
        if not feature_path.exists():
            print(f"⚠️  Skipping {asset}: feature snapshot missing ({feature_path}).")
            continue

        labelled_path = features_dir / f"{asset}_labelled.csv"

        if not args.skip_label:
            label_cmd: List[str] = [
                python,
                "scripts/make_labels.py",
                "--features",
                str(feature_path),
                "--method",
                args.label_method,
                "--asset",
                asset,
                "--price-root",
                str(public_dir),
                "--output",
                str(labelled_path),
            ]
            if args.label_method == "fixed":
                label_cmd.extend([
                    "--horizon",
                    str(max(args.horizon, 1)),
                    "--threshold",
                    str(args.threshold),
                ])
            elif args.label_method == "tbm":
                label_cmd.extend([
                    "--horizon",
                    str(max(args.horizon, 1)),
                    "--pt",
                    str(args.pt),
                    "--sl",
                    str(args.sl),
                ])
            _run_step(f"Label {asset}", label_cmd, env)
        else:
            print(f"⚠️  Skipping labelling for {asset} (requested via --skip-label).")

        if args.skip_train:
            print(f"⚠️  Training skipped for {asset} (requested via --skip-train).")
            continue

        sample_count = _count_labelled_rows(labelled_path, args.label_column)
        if sample_count < max(args.min_samples, 1):
            print(
                "⚠️  Skipping training for {asset}: not enough labelled rows "
                f"({sample_count} < {args.min_samples})."
            )
            continue

        train_cmd: List[str] = [
            python,
            "scripts/train_models.py",
            "--asset",
            asset,
            "--dataset",
            str(labelled_path),
            "--model-dir",
            str(model_dir),
        ]
        if args.dry_run:
            train_cmd.append("--dry-run")
        _run_step(f"Train {asset}", train_cmd, env)

    if not args.skip_readiness and not args.dry_run:
        readiness_cmd = [python, "scripts/check_ml_readiness.py", *assets]
        _run_step("Check ML readiness", readiness_cmd, env)

    return 0


if __name__ == "__main__":  # pragma: no cover - CLI entry point
    raise SystemExit(main())
